{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4c82f9",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f38381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,roc_auc_score\n",
    "\n",
    "#from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e225e",
   "metadata": {},
   "source": [
    "# Load Dataset and Merge Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b12d017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (590540, 434)\n",
      "test: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "#load dataset \n",
    "train_transaction = pd.read_csv(\"/Users/wangjiaxin/Desktop/semester/data science for business/project/train_transaction.csv\")\n",
    "test_transaction = pd.read_csv(\"/Users/wangjiaxin/Desktop/semester/data science for business/project/test_transaction.csv\")\n",
    "train_identity = pd.read_csv(\"/Users/wangjiaxin/Desktop/semester/data science for business/project/train_identity.csv\")\n",
    "test_identity = pd.read_csv(\"/Users/wangjiaxin/Desktop/semester/data science for business/project/test_identity.csv\")\n",
    "#merge table\n",
    "train = pd.merge(train_transaction, train_identity, on = 'TransactionID', how = 'left')\n",
    "test = pd.merge(test_transaction,test_identity, on = 'TransactionID', how = 'left')\n",
    "# change some format of the columns name of test set\n",
    "test= test.rename(columns=lambda x:\"_\".join(x.split(\"-\")))\n",
    "\n",
    "print('train:',train.shape)\n",
    "print('test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a8ce5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung browser 6.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2220x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
       "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
       "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
       "\n",
       "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
       "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
       "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
       "\n",
       "                      DeviceInfo  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4  SAMSUNG SM-G892A Build/NRD90M  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d618d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>card6</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3663549</td>\n",
       "      <td>18403224</td>\n",
       "      <td>31.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10409</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663550</td>\n",
       "      <td>18403263</td>\n",
       "      <td>49.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4272</td>\n",
       "      <td>111.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3663551</td>\n",
       "      <td>18403310</td>\n",
       "      <td>171.00</td>\n",
       "      <td>W</td>\n",
       "      <td>4476</td>\n",
       "      <td>574.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3663552</td>\n",
       "      <td>18403310</td>\n",
       "      <td>284.95</td>\n",
       "      <td>W</td>\n",
       "      <td>10989</td>\n",
       "      <td>360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3663553</td>\n",
       "      <td>18403317</td>\n",
       "      <td>67.95</td>\n",
       "      <td>W</td>\n",
       "      <td>18018</td>\n",
       "      <td>452.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>debit</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt ProductCD  card1  card2  \\\n",
       "0        3663549       18403224           31.95         W  10409  111.0   \n",
       "1        3663550       18403263           49.00         W   4272  111.0   \n",
       "2        3663551       18403310          171.00         W   4476  574.0   \n",
       "3        3663552       18403310          284.95         W  10989  360.0   \n",
       "4        3663553       18403317           67.95         W  18018  452.0   \n",
       "\n",
       "   card3       card4  card5  card6  ...  id_31  id_32  id_33  id_34 id_35  \\\n",
       "0  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "1  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "2  150.0        visa  226.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "3  150.0        visa  166.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "4  150.0  mastercard  117.0  debit  ...    NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "  id_36  id_37  id_38  DeviceType  DeviceInfo  \n",
       "0   NaN    NaN    NaN         NaN         NaN  \n",
       "1   NaN    NaN    NaN         NaN         NaN  \n",
       "2   NaN    NaN    NaN         NaN         NaN  \n",
       "3   NaN    NaN    NaN         NaN         NaN  \n",
       "4   NaN    NaN    NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 433 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d663ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 569877, 1: 20663}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target value\n",
    "c = dict(train['isFraud'].value_counts())\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00905f",
   "metadata": {},
   "source": [
    "# Dealing with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a026afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with missing value\n",
    "def check_value(df):\n",
    "        zero_val = (df == 0.00).astype(int).sum(axis=0)\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n",
    "        mz_table = mz_table.rename(\n",
    "        columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% Missing'})\n",
    "        mz_table['Data Type'] = df.dtypes\n",
    "        mz_table = mz_table[\n",
    "            mz_table.iloc[:,1] != 0].sort_values(\n",
    "        '% Missing', ascending=False).round(1)\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n",
    "            \"There are \" + str(mz_table.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mz_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7362d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 434 columns and 590540 Rows.\n",
      "There are 414 columns that have missing values.\n",
      "       Zero Values  Missing Values  % Missing Data Type  Unique\n",
      "id_24            0          585793       99.2   float64      12\n",
      "id_25            0          585408       99.1   float64     341\n",
      "id_07          409          585385       99.1   float64      84\n",
      "id_08          261          585385       99.1   float64      94\n",
      "id_21            0          585381       99.1   float64     490\n",
      "id_26            0          585377       99.1   float64      95\n",
      "id_27            0          585371       99.1    object       2\n",
      "id_23            0          585371       99.1    object       3\n",
      "id_22            0          585371       99.1   float64      25\n",
      "dist2         3519          552913       93.6   float64    1751\n",
      "D7           21135          551623       93.4   float64     597\n",
      "id_18            0          545427       92.4   float64      18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/fpzdr4sn3lb4rh0wmrtbpxlh0000gn/T/ipykernel_98967/1837566138.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_null_tables['Unique'] = [train[col].nunique() for col in train_null_tables.index ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 433 columns and 506691 Rows.\n",
      "There are 385 columns that have missing values.\n",
      "       Zero Values  Missing Values  % Missing Data Type  Unique\n",
      "id_24            0          501951       99.1   float64      15\n",
      "id_25            0          501652       99.0   float64     309\n",
      "id_26            0          501644       99.0   float64      94\n",
      "id_08          342          501632       99.0   float64      90\n",
      "id_07          527          501632       99.0   float64      81\n",
      "id_21            0          501632       99.0   float64     443\n",
      "id_22            0          501629       99.0   float64      26\n",
      "id_27            0          501629       99.0    object       2\n",
      "id_23            0          501629       99.0    object       3\n",
      "dist2         2821          470255       92.8   float64    1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_k/fpzdr4sn3lb4rh0wmrtbpxlh0000gn/T/ipykernel_98967/1837566138.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_null_tables['Unique'] = [test[col].nunique() for col in test_null_tables.index ]\n"
     ]
    }
   ],
   "source": [
    "Missing_values_table_train = check_value(train)\n",
    "train_null_tables= Missing_values_table_train.loc[Missing_values_table_train['% Missing'] > 90]\n",
    "train_null_tables['Unique'] = [train[col].nunique() for col in train_null_tables.index ]\n",
    "print (train_null_tables)\n",
    "\n",
    "Missing_values_table_test = check_value(test)\n",
    "test_null_tables= Missing_values_table_test.loc[Missing_values_table_test['% Missing'] > 90]\n",
    "test_null_tables['Unique'] = [test[col].nunique() for col in test_null_tables.index ]\n",
    "print (test_null_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333ef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with more than 90% missing values\n",
    "train = train.drop(columns = ['id_24','id_25','id_07','id_08','id_21','id_26','id_27','id_23','id_22','dist2','D7','id_18'])\n",
    "test = test.drop(columns = ['id_24','id_25','id_07','id_08','id_21','id_26','id_27','id_23','id_22','dist2','D7','id_18'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79aff860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with numeric data, fill in with mean \n",
    "for col in train:\n",
    "    if train[col].dtype != 'object':\n",
    "        train[col] = train[col].fillna(train[col].mean())\n",
    "\n",
    "for col in test:\n",
    "    if test[col].dtype != 'object':\n",
    "        test[col] = test[col].fillna(test[col].mean())\n",
    "    \n",
    "#dealing with categorical data, fill in with mode\n",
    "for col in train:\n",
    "    if train[col].dtype == 'object':\n",
    "        train[col] = train[col].fillna(train[col].mode().iloc[0])\n",
    "\n",
    "for col in test:\n",
    "    if test[col].dtype == 'object':\n",
    "        test[col] = test[col].fillna(test[col].mode().iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c42caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in training data set : TransactionID     0\n",
      "isFraud           0\n",
      "TransactionDT     0\n",
      "TransactionAmt    0\n",
      "ProductCD         0\n",
      "                 ..\n",
      "id_36             0\n",
      "id_37             0\n",
      "id_38             0\n",
      "DeviceType        0\n",
      "DeviceInfo        0\n",
      "Length: 422, dtype: int64\n",
      "missing values in testing data set : TransactionID     0\n",
      "TransactionDT     0\n",
      "TransactionAmt    0\n",
      "ProductCD         0\n",
      "card1             0\n",
      "                 ..\n",
      "id_36             0\n",
      "id_37             0\n",
      "id_38             0\n",
      "DeviceType        0\n",
      "DeviceInfo        0\n",
      "Length: 421, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('missing values in training data set :', train.isnull().sum())\n",
    "print('missing values in testing data set :', test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63c778",
   "metadata": {},
   "source": [
    "# Reudece memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8623a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce memory usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6283153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 630.20 Mb (66.9% reduction)\n",
      "Mem. usage decreased to 547.97 Mb (66.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f307d07",
   "metadata": {},
   "source": [
    "# Dealing with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59396168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder to make the categorical data suitable for the machine learning\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(train[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values)) \n",
    "        \n",
    "for f in test.columns:\n",
    "    if test[f].dtype=='object': \n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(test[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04aa02f",
   "metadata": {},
   "source": [
    "# Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5d6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training dataset\n",
    "y = train[\"isFraud\"]\n",
    "X = train.drop([\"isFraud\"], axis=1)\n",
    "\n",
    "# 30% for testing, 70% for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d5de7",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37086f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree classifier\n",
    "model = DecisionTreeClassifier(random_state=1)\n",
    "model.fit(X_train,y_train)\n",
    "predict_y_dt = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f9bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9676567209672503\n",
      "F1 score: 0.559095106186519\n",
      "Area Under the Receiver Operating Characteristic Curve: 0.7837776698540234\n",
      "Confusion maxtrix [[167799   3164]\n",
      " [  2566   3633]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_dt=accuracy_score(y_test,predict_y_dt)\n",
    "f1_score_dt=f1_score(y_test,predict_y_dt)\n",
    "roc_auc_score_dt=roc_auc_score(y_test,predict_y_dt)\n",
    "\n",
    "print('Accuracy score:',accuracy_score_dt)\n",
    "print('F1 score:',f1_score_dt)\n",
    "print('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score_dt)\n",
    "print('Confusion maxtrix',confusion_matrix(y_test,predict_y_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ada37",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "668e2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "forest = RandomForestClassifier(criterion='entropy',random_state=50,n_estimators=100,)\n",
    "forest.fit(X_train,y_train)\n",
    "predict_y_rf = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9842ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9794877005226854\n",
      "F1 score: 0.6004837291116976\n",
      "Area Under the Receiver Operating Characteristic Curve: 0.7197919789436575\n",
      "Confusion maxtrix [[170797    166]\n",
      " [  3468   2731]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_rf=accuracy_score(y_test,predict_y_rf)\n",
    "f1_score_rf=f1_score(y_test,predict_y_rf)\n",
    "roc_auc_score_rf=roc_auc_score(y_test,predict_y_rf)\n",
    "\n",
    "print('Accuracy score:',accuracy_score_rf)\n",
    "print('F1 score:',f1_score_rf)\n",
    "print('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score_rf)\n",
    "print('Confusion maxtrix',confusion_matrix(y_test,predict_y_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc262ecb",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "190a0962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangjiaxin/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression classifier\n",
    "logreg = LogisticRegression()\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "logreg.fit(X_train,y_train)\n",
    "predict_y_logistic=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33e55693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9648344453099423\n",
      "F1 score: 0.0032000000000000006\n",
      "Area Under the Receiver Operating Characteristic Curve: 0.500686672720572\n",
      "Confusion maxtrix [[170922     41]\n",
      " [  6189     10]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_logistic=accuracy_score(y_test,predict_y_logistic)\n",
    "f1_score_logistic=f1_score(y_test,predict_y_logistic)\n",
    "roc_auc_score_logistic=roc_auc_score(y_test,predict_y_logistic)\n",
    "\n",
    "print('Accuracy score:',accuracy_score_logistic)\n",
    "print('F1 score:',f1_score_logistic)\n",
    "print('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score_logistic)\n",
    "print('Confusion maxtrix',confusion_matrix(y_test,predict_y_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d54c683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm\n",
    "#from sklearn import svm\n",
    "#clf = svm.SVC() \n",
    "#clf.fit(X_train,y_train)\n",
    "#predict_y_svm=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef4acc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score_svm=accuracy_score(y_test,predict_y_svm)\n",
    "#f1_score_svm=f1_score(y_test,predict_y_svm)\n",
    "#roc_auc_score_svm=roc_auc_score(y_test,predict_y_svm)\n",
    "\n",
    "#print('Accuracy score:',accuracy_score_svm)\n",
    "#print('F1 score:',f1_score_svm)\n",
    "#print('Area Under the Receiver Operating Characteristic Curve:',roc_auc_score_svm)\n",
    "#print('Confusion maxtrix',confusion_matrix(y_test,predict_y_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45f9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5beb72d",
   "metadata": {},
   "source": [
    "# Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e00a1f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Decision Tree  Random Forest  Logistic Regression\n",
       "0              0              0                    0\n",
       "1              0              0                    0\n",
       "2              0              0                    0\n",
       "3              0              0                    0\n",
       "4              0              0                    0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare with different models\n",
    "#predic_y\n",
    "pred_df= pd.DataFrame({'Decision Tree':predict_y_dt,'Random Forest':predict_y_rf,'Logistic Regression':predict_y_logistic})\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a1d612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>ROC_AUC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.967657</td>\n",
       "      <td>0.559095</td>\n",
       "      <td>0.783778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.979488</td>\n",
       "      <td>0.600484</td>\n",
       "      <td>0.719792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.964834</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.500687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  Accuracy_Score  F1_Score  ROC_AUC_Score\n",
       "0        Decision Tree        0.967657  0.559095       0.783778\n",
       "1        Random Forest        0.979488  0.600484       0.719792\n",
       "2  Logistic Regression        0.964834  0.003200       0.500687"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate\n",
    "evaluate={'model_name':['Decision Tree','Random Forest','Logistic Regression'],\n",
    "         'Accuracy_Score':[accuracy_score_dt,accuracy_score_rf,accuracy_score_logistic],\n",
    "         'F1_Score':[f1_score_dt,f1_score_rf,f1_score_logistic],\n",
    "         'ROC_AUC_Score':[roc_auc_score_dt,roc_auc_score_rf,roc_auc_score_logistic]}\n",
    "pred_df_evaluate=pd.DataFrame(evaluate)\n",
    "pred_df_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1732075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-use model\n",
    "#y_preds = forest.predict_proba(test)\n",
    "#sub_rf = pd.DataFrame({\n",
    "#    'TransactionID' : sub.TransactionID,\n",
    "#    'isFraud' : y_preds[:,1]\n",
    "#})\n",
    "#sub_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4234869a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
